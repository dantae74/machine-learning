{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "04-titanic-machine-learning-from-disaster.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dantae74/machine-learning/blob/main/kaggle/04-titanic-machine-learning-from-disaster.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfgQSbgOoe-2"
      },
      "source": [
        "### kaggle 에서 가져왔습니다.\n",
        "\n",
        "# Titanic - Machine Learning from Diaster"
      ],
      "id": "WfgQSbgOoe-2"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import sklearn\n",
        "import xgboost as xgb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "pO0JtS3YSEeq"
      },
      "id": "pO0JtS3YSEeq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# kaggle에서 titanic 데이터 셋 가져오기"
      ],
      "metadata": {
        "id": "WUsyfLUDQEWL"
      },
      "id": "WUsyfLUDQEWL"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "P1FQF2c_QOqu"
      },
      "id": "P1FQF2c_QOqu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "GSaaZQEOQOcv"
      },
      "id": "GSaaZQEOQOcv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "7pUVFxwMQOPo"
      },
      "id": "7pUVFxwMQOPo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "HhgoZ4kIRin6"
      },
      "id": "HhgoZ4kIRin6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c titanic"
      ],
      "metadata": {
        "id": "nzlGcSjsRlPX"
      },
      "id": "nzlGcSjsRlPX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls"
      ],
      "metadata": {
        "id": "IbetDQTQSPJz"
      },
      "id": "IbetDQTQSPJz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "7WxO8zHHKVBS"
      },
      "id": "7WxO8zHHKVBS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Going to use these 5 base models for the stacking\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "RMrubStgKfxp"
      },
      "id": "RMrubStgKfxp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Exploration, Engineering and Cleaning"
      ],
      "metadata": {
        "id": "d0gdejsuOgOf"
      },
      "id": "d0gdejsuOgOf"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the train and test datasets\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "gMulSOw4MIgB"
      },
      "id": "gMulSOw4MIgB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store our passenger ID for easy access\n",
        "PassengerId = test['PassengerId']"
      ],
      "metadata": {
        "id": "cyjGlNxFSC7m"
      },
      "id": "cyjGlNxFSC7m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(3)"
      ],
      "metadata": {
        "id": "6u5UbQw_uZeq"
      },
      "id": "6u5UbQw_uZeq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = [train, test]"
      ],
      "metadata": {
        "id": "mXS2T3LBurhx"
      },
      "id": "mXS2T3LBurhx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some features of my own that I have added in\n",
        "# Gives the length of the name\n",
        "train['Name_length'] = train['Name'].apply(len)\n",
        "test['Name_length'] = test['Name'].apply(len)"
      ],
      "metadata": {
        "id": "dArjWwSUvTlu"
      },
      "id": "dArjWwSUvTlu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature that tells whether a passenger had a cabin on the Titanic\n",
        "train['Has_Cabin'] = train['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
        "test['Has_Cabin'] = test['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)"
      ],
      "metadata": {
        "id": "04xJrKv-vVw4"
      },
      "id": "04xJrKv-vVw4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering steps taken from Sina\n",
        "# Create new feature FamilySize as a combination of SibSp and Parch\n",
        "for dataset in full_data:\n",
        "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1"
      ],
      "metadata": {
        "id": "eLo_Jjup0TLs"
      },
      "id": "eLo_Jjup0TLs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new feature IsAlone from FamilySize\n",
        "for dataset in full_data:\n",
        "    dataset['IsAlone'] = 0\n",
        "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1"
      ],
      "metadata": {
        "id": "A_TECsCEkQCG"
      },
      "id": "A_TECsCEkQCG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all NULLS in the Embarked column\n",
        "for dataset in full_data:\n",
        "  dataset['Embarked'] = dataset['Embarked'].fillna('S')"
      ],
      "metadata": {
        "id": "Xa295IvtkSi9"
      },
      "id": "Xa295IvtkSi9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
        "for dataset in full_data:\n",
        "  dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
        "\n",
        "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)"
      ],
      "metadata": {
        "id": "GKYvQYZ2kYOF"
      },
      "id": "GKYvQYZ2kYOF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a New feature CategoricalAge\n",
        "for dataset in full_data:\n",
        "  age_avg = dataset['Age'].mean()\n",
        "  age_std = dataset['Age'].std()\n",
        "  age_null_count = dataset['Age'].isnull().sum()\n",
        "  age_null_random_list = np.random.randint(age_avg-age_std, age_avg+age_std, size=age_null_count, dtype=int)\n",
        "  dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
        "  dataset['Age'] = dataset['Age'].astype(int)\n",
        "  \n",
        "train['CategoricalAge'] = pd.qcut(train['Age'], 5)"
      ],
      "metadata": {
        "id": "u2wMd1j_kl4n"
      },
      "id": "u2wMd1j_kl4n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to extract titles from passenger names\n",
        "def get_title(name):\n",
        "  title_search = re.search('([a-zA-Z]+)\\.', name)\n",
        "  if title_search:\n",
        "    return title_search.group(1)\n",
        "  return \"\""
      ],
      "metadata": {
        "id": "iUADqctqkaav"
      },
      "id": "iUADqctqkaav",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new feature Title, containing the titles of passenger names\n",
        "for dataset in full_data:\n",
        "  dataset['Title'] = dataset['Name'].apply(get_title)"
      ],
      "metadata": {
        "id": "lFw0RpfQ8pwc"
      },
      "id": "lFw0RpfQ8pwc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group all non-common titles into one single grouping \"Rare\"\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')"
      ],
      "metadata": {
        "id": "7h6FlbNg8ptS"
      },
      "id": "7h6FlbNg8ptS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in full_data:\n",
        "    # Mapping Sex\n",
        "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
        "    \n",
        "    # Mapping titles\n",
        "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "    \n",
        "    # Mapping Embarked\n",
        "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "    \n",
        "    # Mapping Fare\n",
        "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
        "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
        "    \n",
        "    # Mapping Age\n",
        "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
        "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
        "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ;"
      ],
      "metadata": {
        "id": "ZUqdEAom_kGh"
      },
      "id": "ZUqdEAom_kGh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection\n",
        "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
        "train = train.drop(drop_elements, axis = 1)\n",
        "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
        "test  = test.drop(drop_elements, axis = 1)"
      ],
      "metadata": {
        "id": "Ywk_xEdJANRY"
      },
      "id": "Ywk_xEdJANRY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "r0lVBZWmBruB"
      },
      "id": "r0lVBZWmBruB"
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "TcueTO118pqk"
      },
      "id": "TcueTO118pqk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pearson Correlation Heatmap"
      ],
      "metadata": {
        "id": "CzQ12FfSCNIi"
      },
      "id": "CzQ12FfSCNIi"
    },
    {
      "cell_type": "code",
      "source": [
        "colormap = plt.cm.RdBu\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
        "sns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
        "            square=True, cmap=colormap, linecolor='white', annot=True)"
      ],
      "metadata": {
        "id": "qerzw6QFCR-l"
      },
      "id": "qerzw6QFCR-l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uCuanysECn1v"
      },
      "id": "uCuanysECn1v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I3biddJ5COuM"
      },
      "id": "I3biddJ5COuM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QV65SsxDCMI1"
      },
      "id": "QV65SsxDCMI1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QdzVvt3YB4aM"
      },
      "id": "QdzVvt3YB4aM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FZIgybuy8pnn"
      },
      "id": "FZIgybuy8pnn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Br2tB_-i8plK"
      },
      "id": "Br2tB_-i8plK",
      "execution_count": null,
      "outputs": []
    }
  ]
}