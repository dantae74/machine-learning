{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "04-titanic-machine-learning-from-disaster.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dantae74/machine-learning/blob/main/kaggle/04-titanic-machine-learning-from-disaster.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfgQSbgOoe-2"
      },
      "source": [
        "### kaggle 에서 가져왔습니다.\n",
        "\n",
        "# Titanic - Machine Learning from Diaster"
      ],
      "id": "WfgQSbgOoe-2"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import sklearn\n",
        "import xgboost as xgb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "pO0JtS3YSEeq"
      },
      "id": "pO0JtS3YSEeq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# kaggle에서 titanic 데이터 셋 가져오기"
      ],
      "metadata": {
        "id": "WUsyfLUDQEWL"
      },
      "id": "WUsyfLUDQEWL"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "P1FQF2c_QOqu"
      },
      "id": "P1FQF2c_QOqu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "GSaaZQEOQOcv"
      },
      "id": "GSaaZQEOQOcv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "7pUVFxwMQOPo"
      },
      "id": "7pUVFxwMQOPo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "HhgoZ4kIRin6"
      },
      "id": "HhgoZ4kIRin6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c titanic"
      ],
      "metadata": {
        "id": "nzlGcSjsRlPX"
      },
      "id": "nzlGcSjsRlPX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls"
      ],
      "metadata": {
        "id": "IbetDQTQSPJz"
      },
      "id": "IbetDQTQSPJz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "7WxO8zHHKVBS"
      },
      "id": "7WxO8zHHKVBS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Going to use these 5 base models for the stacking\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "RMrubStgKfxp"
      },
      "id": "RMrubStgKfxp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Exploration, Engineering and Cleaning"
      ],
      "metadata": {
        "id": "d0gdejsuOgOf"
      },
      "id": "d0gdejsuOgOf"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the train and test datasets\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "gMulSOw4MIgB"
      },
      "id": "gMulSOw4MIgB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store our passenger ID for easy access\n",
        "PassengerId = test['PassengerId']"
      ],
      "metadata": {
        "id": "cyjGlNxFSC7m"
      },
      "id": "cyjGlNxFSC7m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(3)"
      ],
      "metadata": {
        "id": "6u5UbQw_uZeq"
      },
      "id": "6u5UbQw_uZeq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = [train, test]"
      ],
      "metadata": {
        "id": "mXS2T3LBurhx"
      },
      "id": "mXS2T3LBurhx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some features of my own that I have added in\n",
        "# Gives the length of the name\n",
        "train['Name_length'] = train['Name'].apply(len)\n",
        "test['Name_length'] = test['Name'].apply(len)"
      ],
      "metadata": {
        "id": "dArjWwSUvTlu"
      },
      "id": "dArjWwSUvTlu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature that tells whether a passenger had a cabin on the Titanic\n",
        "train['Has_Cabin'] = train['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
        "test['Has_Cabin'] = test['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)"
      ],
      "metadata": {
        "id": "04xJrKv-vVw4"
      },
      "id": "04xJrKv-vVw4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering steps taken from Sina\n",
        "# Create new feature FamilySize as a combination of SibSp and Parch\n",
        "for dataset in full_data:\n",
        "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1"
      ],
      "metadata": {
        "id": "eLo_Jjup0TLs"
      },
      "id": "eLo_Jjup0TLs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new feature IsAlone from FamilySize\n",
        "for dataset in full_data:\n",
        "    dataset['IsAlone'] = 0\n",
        "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1"
      ],
      "metadata": {
        "id": "A_TECsCEkQCG"
      },
      "id": "A_TECsCEkQCG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all NULLS in the Embarked column\n",
        "for dataset in full_data:\n",
        "  dataset['Embarked'] = dataset['Embarked'].fillna('S')"
      ],
      "metadata": {
        "id": "Xa295IvtkSi9"
      },
      "id": "Xa295IvtkSi9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
        "for dataset in full_data:\n",
        "  dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
        "\n",
        "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)"
      ],
      "metadata": {
        "id": "GKYvQYZ2kYOF"
      },
      "id": "GKYvQYZ2kYOF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a New feature CategoricalAge\n",
        "for dataset in full_data:\n",
        "  age_avg = dataset['Age'].mean()\n",
        "  age_std = dataset['Age'].std()\n",
        "  age_null_count = dataset['Age'].isnull().sum()\n",
        "  age_null_random_list = np.random.randint(age_avg-age_std, age_avg+age_std, size=age_null_count, dtype=int)\n",
        "  dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
        "  dataset['Age'] = dataset['Age'].astype(int)\n",
        "  \n",
        "train['CategoricalAge'] = pd.qcut(train['Age'], 5)"
      ],
      "metadata": {
        "id": "u2wMd1j_kl4n"
      },
      "id": "u2wMd1j_kl4n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iUADqctqkaav"
      },
      "id": "iUADqctqkaav",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wPpVtlgX14HV"
      },
      "id": "wPpVtlgX14HV",
      "execution_count": null,
      "outputs": []
    }
  ]
}